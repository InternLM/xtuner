<div align="center">
  <img src="https://github.com/InternLM/lmdeploy/assets/36994684/0cf8d00f-e86b-40ba-9b54-dc8f1bc6c8d8" width="600"/>
  <br /><br />

[![GitHub Repo stars](https://img.shields.io/github/stars/InternLM/xtuner?style=social)](https://github.com/InternLM/xtuner/stargazers)
[![license](https://img.shields.io/github/license/InternLM/xtuner.svg)](https://github.com/InternLM/xtuner/blob/main/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/xtuner)](https://pypi.org/project/xtuner/)
[![Downloads](https://static.pepy.tech/badge/xtuner)](https://pypi.org/project/xtuner/)
[![issue resolution](https://img.shields.io/github/issues-closed-raw/InternLM/xtuner)](https://github.com/InternLM/xtuner/issues)
[![open issues](https://img.shields.io/github/issues-raw/InternLM/xtuner)](https://github.com/InternLM/xtuner/issues)

ğŸ‘‹ åŠ å…¥æˆ‘ä»¬ï¼š[![Static Badge](https://img.shields.io/badge/-grey?style=social&logo=wechat&label=å¾®ä¿¡)](https://cdn.vansin.top/internlm/xtuner.jpg)
[![Static Badge](https://img.shields.io/badge/-grey?style=social&logo=twitter&label=æ¨ç‰¹)](https://twitter.com/intern_lm)
[![Static Badge](https://img.shields.io/badge/-grey?style=social&logo=discord&label=Discord)](https://discord.gg/xa29JuW87d)

ğŸ” æ¢ç´¢æˆ‘ä»¬çš„æ¨¡å‹ï¼š
[![Static Badge](https://img.shields.io/badge/-gery?style=social&label=ğŸ¤—%20Huggingface)](https://huggingface.co/xtuner)
[![Static Badge](https://img.shields.io/badge/-gery?style=social&label=ğŸ¤–%20ModelScope)](https://www.modelscope.cn/organization/xtuner)
[![Static Badge](https://img.shields.io/badge/-gery?style=social&label=ğŸ§°%20OpenXLab)](https://openxlab.org.cn/usercenter/xtuner)
[![Static Badge](https://img.shields.io/badge/-gery?style=social&label=ğŸ§ %20WiseModel)](https://www.wisemodel.cn/organization/xtuner)

[English](README.md) | ç®€ä½“ä¸­æ–‡

</div>




## ğŸš€ Speed Benchmark

<div align=center>
  <img src="https://github.com/user-attachments/assets/fa42d587-068d-427b-b88c-25a164b3511c" style="width:80%">
</div>


## ğŸ‰ æ›´æ–°

- **\[2025/09\]** XTuner V1 æ­£å¼å‘å¸ƒï¼ä¸“ä¸ºè¶…å¤§è§„æ¨¡ MoE æ¨¡å‹æ‰“é€ çš„æ–°ä¸€ä»£è®­ç»ƒå¼•æ“


## ğŸ“–  ä»‹ç»

XTuner V1 æ˜¯ä¸€ä¸ªä¸“ä¸ºè¶…å¤§è§„æ¨¡ MoE æ¨¡å‹æ‰“é€ çš„æ–°ä¸€ä»£å¤§æ¨¡å‹è®­ç»ƒå¼•æ“ã€‚ä¸ä¼ ç»Ÿ 3D å¹¶è¡Œè®­ç»ƒæ¶æ„ç›¸æ¯”ï¼ŒXTuner V1 é’ˆå¯¹å½“å‰å­¦æœ¯ç•Œä¸»æµçš„ MoE è®­ç»ƒåœºæ™¯è¿›è¡Œäº†æ·±åº¦ä¼˜åŒ–ã€‚


### æ ¸å¿ƒç‰¹æ€§

**ğŸ“Š Dropless è®­ç»ƒ**
- **çµæ´»æ‰©å±•ï¼Œæ— éœ€å¤æ‚é…ç½®ï¼š** 200B é‡çº§ MoE æ— éœ€ä¸“å®¶å¹¶è¡Œï¼›600B MoE ä»…éœ€èŠ‚ç‚¹å†…ä¸“å®¶å¹¶è¡Œ
- **ä¼˜åŒ–çš„å¹¶è¡Œç­–ç•¥ï¼š** ç›¸æ¯”ä¼ ç»Ÿ 3D å¹¶è¡Œæ–¹æ¡ˆï¼Œä¸“å®¶å¹¶è¡Œç»´åº¦æ›´å°ï¼Œå®ç°æ›´é«˜æ•ˆçš„ Dropless è®­ç»ƒ


**ğŸ“ é•¿åºåˆ—æ”¯æŒ**
- **å†…å­˜é«˜æ•ˆè®¾è®¡ï¼š** é€šè¿‡å…ˆè¿›çš„æ˜¾å­˜ä¼˜åŒ–æŠ€æœ¯ç»„åˆï¼Œ200B MoE æ¨¡å‹æ— éœ€åºåˆ—å¹¶è¡Œå³å¯è®­ç»ƒ 64k åºåˆ—é•¿åº¦
- **çµæ´»æ‰©å±•èƒ½åŠ›ï¼š** å…¨é¢æ”¯æŒ DeepSpeed Ulysses åºåˆ—å¹¶è¡Œï¼Œæœ€å¤§åºåˆ—é•¿åº¦å¯çº¿æ€§æ‰©å±•
- **ç¨³å®šå¯é ï¼š** é•¿åºåˆ—è®­ç»ƒæ—¶å¯¹ä¸“å®¶è´Ÿè½½ä¸å‡è¡¡ä¸æ•æ„Ÿï¼Œä¿æŒç¨³å®šæ€§èƒ½


**âš¡ å“è¶Šæ•ˆç‡**

- **è¶…å¤§è§„æ¨¡æ”¯æŒï¼š** æ”¯æŒé«˜è¾¾ 1T å‚æ•°é‡çš„ MoE æ¨¡å‹è®­ç»ƒ
- **çªç ´æ€§èƒ½ç“¶é¢ˆï¼š** é¦–æ¬¡åœ¨ 200B ä»¥ä¸Šè§„æ¨¡çš„ MoE æ¨¡å‹ä¸Šï¼Œå®ç° FSDP è®­ç»ƒååè¶…è¶Šä¼ ç»Ÿ 3D å¹¶è¡Œæ–¹æ¡ˆ
- **ç¡¬ä»¶ä¼˜åŒ–ï¼š** åœ¨ Ascend A3 NPU è¶…èŠ‚ç‚¹ä¸Šï¼Œè®­ç»ƒæ•ˆç‡è¶…è¶Š NVIDIA H800


<div align=center>
  <img src="https://github.com/user-attachments/assets/98519a93-1ce8-49f0-a7ab-d7968c9d67a6" style="width:90%">
</div>


## ğŸ”¥ Roadmap

XTuner V1 è‡´åŠ›äºæŒç»­æå‡è¶…å¤§è§„æ¨¡ MoE æ¨¡å‹çš„é¢„è®­ç»ƒã€æŒ‡ä»¤å¾®è°ƒå’Œå¼ºåŒ–å­¦ä¹ è®­ç»ƒæ•ˆç‡ï¼Œå¹¶é‡ç‚¹ä¼˜åŒ–æ˜‡è…¾ NPU æ”¯æŒã€‚

### ğŸš€ è®­ç»ƒå¼•æ“

æˆ‘ä»¬çš„æ„¿æ™¯æ˜¯å°† XTuner V1 æ‰“é€ æˆé€šç”¨è®­ç»ƒåç«¯ï¼Œæ— ç¼é›†æˆåˆ°æ›´å¹¿æ³›çš„å¼€æºç”Ÿæ€ç³»ç»Ÿä¸­ã€‚

|   Model    |  GPU(FP8) | GPU(BF16)| NPU(BF16) |
|------------|-----------|----------|-----------|
| Intern S1  |    âœ…     |    âœ…    |    âœ…     |
| Intern VL  |    âœ…     |    âœ…    |    âœ…     |
| Qwen3 Dense|    âœ…     |    âœ…    |    âœ…     |
| Qwen3 MoE  |    âœ…     |    âœ…    |    âœ…     |
| GPT OSS    |    âœ…     |    âœ…    |    âŒ     |
| Deepseek V3|    âœ…     |    âœ…    |    âŒ     |
| KIMI K2    |    âœ…     |    âœ…    |    âŒ     |


### ğŸ§  ç®—æ³•å¥—ä»¶

ç®—æ³•ç»„ä»¶æ­£åœ¨å¿«é€Ÿè¿­ä»£ä¸­ã€‚æ¬¢è¿ç¤¾åŒºè´¡çŒ® - ä½¿ç”¨ XTuner V1ï¼Œå°†æ‚¨çš„ç®—æ³•æ‰©å±•åˆ°å‰æ‰€æœªæœ‰çš„è§„æ¨¡ï¼

**å·²å®ç°**

- âœ… **å¤šæ¨¡æ€é¢„è®­ç»ƒ** - å…¨é¢æ”¯æŒè§†è§‰è¯­è¨€æ¨¡å‹è®­ç»ƒ
- âœ… **å¤šæ¨¡æ€ç›‘ç£å¾®è°ƒ** - é’ˆå¯¹æŒ‡ä»¤è·Ÿéšä¼˜åŒ–
- âœ… [GRPO](https://arxiv.org/pdf/2402.03300) - Group Relative Policy Optimization

**å³å°†æ¨å‡º**

- ğŸ”„ [MPO](https://arxiv.org/pdf/2411.10442) - Mixed Preference Optimization
- ğŸ”„ [DAPO](https://arxiv.org/pdf/2503.14476) - Dynamic Sampling Policy Optimization
- ğŸ”„ **å¤šè½®æ™ºèƒ½ä½“å¼ºåŒ–å­¦ä¹ ** - é«˜çº§æ™ºèƒ½ä½“è®­ç»ƒèƒ½åŠ›


### âš¡ æ¨ç†å¼•æ“é›†æˆ

ä¸ä¸»æµæ¨ç†æ¡†æ¶æ— ç¼å¯¹æ¥

- [x] LMDeploy
- [ ] vLLM
- [ ] SGLang



### æ•°æ®

- æ¨èä½¿ç”¨ [GraphGen](https://github.com/open-sciencelab/GraphGen) åˆæˆ SFT æ‰€éœ€è®­ç»ƒæ•°æ®ï¼Œç›®å‰å·²åœ¨å¤šä¸ªå‚åŸŸéªŒè¯æ•ˆæœã€‚

## ğŸ¤ è´¡çŒ®æŒ‡å—

æˆ‘ä»¬æ„Ÿè°¢æ‰€æœ‰çš„è´¡çŒ®è€…ä¸ºæ”¹è¿›å’Œæå‡ XTuner æ‰€ä½œå‡ºçš„åŠªåŠ›ã€‚è¯·å‚è€ƒ[è´¡çŒ®æŒ‡å—](.github/CONTRIBUTING.md)æ¥äº†è§£å‚ä¸é¡¹ç›®è´¡çŒ®çš„ç›¸å…³æŒ‡å¼•ã€‚

## ğŸ™ è‡´è°¢

XTuner V1 çš„å¼€å‘æ·±å—å¼€æºç¤¾åŒºä¼˜ç§€é¡¹ç›®çš„å¯å‘å’Œæ”¯æŒã€‚æˆ‘ä»¬å‘ä»¥ä¸‹å¼€åˆ›æ€§é¡¹ç›®è‡´ä»¥è¯šæŒšçš„è°¢æ„ï¼š

**è®­ç»ƒå¼•æ“ï¼š**

- [Torchtitan](https://github.com/pytorch/torchtitan) - PyTorch åŸç”Ÿåˆ†å¸ƒå¼è®­ç»ƒæ¡†æ¶
- [Deepspeed](https://github.com/deepspeedai/DeepSpeed) - å¾®è½¯æ·±åº¦å­¦ä¹ ä¼˜åŒ–åº“	
- [MindSpeed](https://gitee.com/ascend/MindSpeed) - æ˜‡è…¾é«˜æ€§èƒ½è®­ç»ƒåŠ é€Ÿåº“
- [Megatron](https://github.com/NVIDIA/Megatron-LM) - NVIDIA å¤§è§„æ¨¡ Transformer è®­ç»ƒæ¡†æ¶


**å¼ºåŒ–å­¦ä¹ ï¼š**

XTuner V1 çš„å¼ºåŒ–å­¦ä¹ èƒ½åŠ›å€Ÿé‰´äº†ä»¥ä¸‹é¡¹ç›®çš„ä¼˜ç§€å®è·µå’Œç»éªŒ

- [veRL](https://github.com/volcengine/verl) - Volcano Engine Reinforcement Learning for LLMs	
- [SLIME](https://github.com/THUDM/slime) - THU's scalable RLHF implementation	
- [AReal](https://github.com/inclusionAI/AReaL) - Ant Reasoning Reinforcement Learning for LLMs
- [OpenRLHF](https://github.com/OpenRLHF/OpenRLHF) - An Easy-to-use, Scalable and High-performance RLHF Framework based on Ray

æˆ‘ä»¬è¡·å¿ƒæ„Ÿè°¢è¿™äº›é¡¹ç›®çš„æ‰€æœ‰è´¡çŒ®è€…å’Œç»´æŠ¤è€…ï¼Œæ˜¯ä»–ä»¬æ¨åŠ¨äº†å¤§è§„æ¨¡æ¨¡å‹è®­ç»ƒé¢†åŸŸçš„ä¸æ–­è¿›æ­¥ã€‚
## ğŸ–Šï¸ å¼•ç”¨

```bibtex
@misc{2023xtuner,
    title={XTuner: A Toolkit for Efficiently Fine-tuning LLM},
    author={XTuner Contributors},
    howpublished = {\url{https://github.com/InternLM/xtuner}},
    year={2023}
}
```

## å¼€æºè®¸å¯è¯

è¯¥é¡¹ç›®é‡‡ç”¨ [Apache License 2.0 å¼€æºè®¸å¯è¯](LICENSE)ã€‚åŒæ—¶ï¼Œè¯·éµå®ˆæ‰€ä½¿ç”¨çš„æ¨¡å‹ä¸æ•°æ®é›†çš„è®¸å¯è¯ã€‚
