<div align="center">
  <img src="https://github.com/InternLM/lmdeploy/assets/36994684/0cf8d00f-e86b-40ba-9b54-dc8f1bc6c8d8" width="600"/>
  <br /><br />

[![license](https://img.shields.io/github/license/InternLM/xtuner.svg)](https://github.com/InternLM/xtuner/blob/main/LICENSE)
[![PyPI](https://badge.fury.io/py/xtuner.svg)](https://pypi.org/project/xtuner/)
[![Generic badge](https://img.shields.io/badge/ğŸ¤—%20Huggingface-xtuner-yellow.svg)](https://huggingface.co/xtuner)

[English](README.md) | ç®€ä½“ä¸­æ–‡

ğŸ‘‹ åŠ å…¥æˆ‘ä»¬ï¼š<a href="https://twitter.com/intern_lm" target="_blank">æ¨ç‰¹</a>ã€<a href="https://discord.gg/xa29JuW87d" target="_blank">Discord</a>ã€<a href="https://cdn.vansin.top/internlm/xtuner.jpg" target="_blank">å¾®ä¿¡</a>

</div>

## ğŸ‰ æ›´æ–°

- **\[2023.09.20\]** æ”¯æŒ [InternLM-20B](https://huggingface.co/internlm) ç³»åˆ—æ¨¡å‹ï¼
- **\[2023.09.06\]** æ”¯æŒ [Baichuan2](https://huggingface.co/baichuan-inc) ç³»åˆ—æ¨¡å‹ï¼
- **\[2023.08.30\]** XTuner æ­£å¼å‘å¸ƒï¼ä¼—å¤šå¾®è°ƒæ¨¡å‹å·²ä¸Šä¼ è‡³ [HuggingFace](https://huggingface.co/xtuner)ï¼

## ğŸ“– ä»‹ç»

XTuner æ˜¯ä¸€ä¸ªè½»é‡çº§å¾®è°ƒå¤§è¯­è¨€æ¨¡å‹çš„å·¥å…·åº“ï¼Œç”± [MMRazor](https://github.com/open-mmlab/mmrazor) å’Œ [MMDeploy](https://github.com/open-mmlab/mmdeploy) å›¢é˜Ÿè”åˆå¼€å‘ã€‚

- **è½»é‡çº§**: æ”¯æŒåœ¨æ¶ˆè´¹çº§æ˜¾å¡ä¸Šå¾®è°ƒå¤§è¯­è¨€æ¨¡å‹ã€‚å¯¹äº 7B å‚æ•°é‡ï¼Œå¾®è°ƒæ‰€éœ€çš„æœ€å°æ˜¾å­˜ä»…ä¸º **8GB**ï¼Œè¿™ä½¿å¾—ç”¨æˆ·å¯ä»¥ä½¿ç”¨å‡ ä¹ä»»ä½•æ˜¾å¡ï¼ˆç”šè‡³å…è´¹èµ„æºï¼Œä¾‹å¦‚Colabï¼‰æ¥å¾®è°ƒè·å¾—è‡ªå®šä¹‰å¤§è¯­è¨€æ¨¡å‹åŠ©æ‰‹ã€‚
- **å¤šæ ·æ€§**: æ”¯æŒå¤šç§**å¤§è¯­è¨€æ¨¡å‹**ï¼ˆ[InternLM](https://huggingface.co/internlm)ã€[Llama2](https://huggingface.co/meta-llama)ã€[ChatGLM2](https://huggingface.co/THUDM/chatglm2-6b)ã€[Qwen](https://huggingface.co/Qwen)ã€[Baichuan2](https://huggingface.co/baichuan-inc), ...ï¼‰ï¼Œ**æ•°æ®é›†**ï¼ˆ[MOSS_003_SFT](https://huggingface.co/datasets/fnlp/moss-003-sft-data), [Alpaca](https://huggingface.co/datasets/tatsu-lab/alpaca), [WizardLM](https://huggingface.co/datasets/WizardLM/WizardLM_evol_instruct_V2_196k), [oasst1](https://huggingface.co/datasets/timdettmers/openassistant-guanaco), [Open-Platypus](https://huggingface.co/datasets/garage-bAInd/Open-Platypus), [Code Alpaca](https://huggingface.co/datasets/HuggingFaceH4/CodeAlpaca_20K), [Colorist](https://huggingface.co/datasets/burkelibbey/colors), ...ï¼‰å’Œ**å¾®è°ƒç®—æ³•**ï¼ˆ[QLoRA](http://arxiv.org/abs/2305.14314)ã€[LoRA](http://arxiv.org/abs/2106.09685)ï¼‰ï¼Œæ”¯æ’‘ç”¨æˆ·æ ¹æ®è‡ªèº«å…·ä½“éœ€æ±‚é€‰æ‹©åˆé€‚çš„è§£å†³æ–¹æ¡ˆã€‚
- **å…¼å®¹æ€§**: å…¼å®¹ [DeepSpeed](https://github.com/microsoft/DeepSpeed) ğŸš€ å’Œ [HuggingFace](https://huggingface.co) ğŸ¤— çš„è®­ç»ƒæµç¨‹ï¼Œæ”¯æ’‘ç”¨æˆ·æ— æ„Ÿå¼é›†æˆä¸ä½¿ç”¨ã€‚

## ğŸŒŸ ç¤ºä¾‹

- XTuner APIsæ‰€æä¾›çš„å¼€ç®±å³ç”¨çš„æ¨¡å‹ä¸æ•°æ®é›† [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/drive/1eBI9yiOkX-t7P-0-t9vS8y1x5KmWrkoU?usp=sharing)

- QLoRA å¾®è°ƒ [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/drive/1QAEZVBfQ7LZURkMUtaq0b-5nEQII9G9Z?usp=sharing)

- åŸºäºæ’ä»¶çš„å¯¹è¯ [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/drive/144OuTVyT_GvFyDMtlSlTzcxYIfnRsklq?usp=sharing)

  <table>
  <tr>
    <th colspan="3" align="center">åŸºäºæ’ä»¶çš„å¯¹è¯ ğŸ”¥ğŸ”¥ğŸ”¥</th>
  </tr>
  <tr>
  <td>
  <a><img src="https://github.com/InternLM/lmdeploy/assets/36994684/7c429d98-7630-4539-8aff-c89094826f8c"></a>
  </td>
  <td>
  <a><img src="https://github.com/InternLM/lmdeploy/assets/36994684/05d02906-5a82-45bc-b4e3-2cc32d473b2c"></a>
  </td>
  <td>
  <a><img src="https://github.com/InternLM/lmdeploy/assets/36994684/80395303-997a-47f2-b7d2-d585034df683"></a>
  </td>
  </tr>
  </table>

## ğŸ”¥ æ”¯æŒåˆ—è¡¨

<table>
<tbody>
<tr align="center" valign="middle">
<td>
  <b>æ¨¡å‹</b>
</td>
<td>
  <b>æ•°æ®é›†</b>
</td>
<td>
  <b>æ•°æ®æ ¼å¼</b>
</td>
 <td>
  <b>å¾®è°ƒç®—æ³•</b>
</td>
</tr>
<tr valign="top">
<td align="left" valign="top">
<ul>
  <li><a href="https://huggingface.co/internlm/internlm-7b">InternLM</a></li>
  <li><a href="https://huggingface.co/meta-llama">Llama</a></li>
  <li><a href="https://huggingface.co/meta-llama">Llama2</a></li>
  <li><a href="https://huggingface.co/THUDM/chatglm2-6b">ChatGLM2</a></li>
  <li><a href="https://huggingface.co/Qwen/Qwen-7B">Qwen</a></li>
  <li><a href="https://huggingface.co/baichuan-inc/Baichuan-7B">Baichuan</a></li>
  <li><a href="https://huggingface.co/baichuan-inc/Baichuan2-7B-Base">Baichuan2</a></li>
  <li>...</li>
</ul>
</td>
<td>
<ul>
  <li><a href="https://huggingface.co/datasets/fnlp/moss-003-sft-data">MOSS-003-SFT</a> ğŸ”§</li>
  <li><a href="https://huggingface.co/datasets/tatsu-lab/alpaca">Alpaca en</a> / <a href="https://huggingface.co/datasets/silk-road/alpaca-data-gpt4-chinese">zh</a></li>
  <li><a href="https://huggingface.co/datasets/WizardLM/WizardLM_evol_instruct_V2_196k">WizardLM</a></li>
  <li><a href="https://huggingface.co/datasets/timdettmers/openassistant-guanaco">oasst1</a></li>
  <li><a href="https://huggingface.co/datasets/garage-bAInd/Open-Platypus">Open-Platypus</a></li>
  <li><a href="https://huggingface.co/datasets/HuggingFaceH4/CodeAlpaca_20K">Code Alpaca</a></li>
  <li><a href="https://huggingface.co/datasets/burkelibbey/colors">Colorist</a> ğŸ¨</li>
  <li><a href="https://github.com/WangRongsheng/ChatGenTitle">Arxiv GenTitle</a></li>
  <li><a href="https://github.com/LiuHC0428/LAW-GPT">Chinese Law</a></li>
  <li><a href="https://huggingface.co/datasets/Open-Orca/OpenOrca">OpenOrca</a></li>
  <li><a href="https://huggingface.co/datasets/shibing624/medical">Medical Dialogue</a></li>
  <li>...</li>
</ul>
</td>
<td>
<ul>
  <li><a href="docs/zh_cn/user_guides/incremental_pretraining.md">Incremental Pre-training</a> </li>
  <li><a href="docs/zh_cn/user_guides/single_turn_conversation.md">Single-turn Conversation SFT</a> </li>
  <li><a href="docs/zh_cn/user_guides/multi_turn_conversation.md">Multi-turn Conversation SFT</a> </li>
</ul>
</td>
<td>
<ul>
  <li><a href="http://arxiv.org/abs/2305.14314">QLoRA</a></li>
  <li><a href="http://arxiv.org/abs/2106.09685">LoRA</a></li>
  <li>å…¨é‡å‚æ•°å¾®è°ƒ</li>
</ul>
</td>
</tr>
</tbody>
</table>

## ğŸ› ï¸ å¿«é€Ÿä¸Šæ‰‹

### å®‰è£…

- é€šè¿‡ pip å®‰è£… XTunerï¼š

  ```shell
  pip install xtuner
  ```

  äº¦å¯é›†æˆ DeepSpeed å®‰è£…ï¼š

  ```shell
  pip install 'xtuner[deepspeed]'
  ```

- ä»æºç å®‰è£… XTunerï¼š

  ```shell
  git clone https://github.com/InternLM/xtuner.git
  cd xtuner
  pip install -e '.[all]'
  ```

### å¾®è°ƒ [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/drive/1QAEZVBfQ7LZURkMUtaq0b-5nEQII9G9Z?usp=sharing)

XTuner æ”¯æŒå¾®è°ƒå¤§è¯­è¨€æ¨¡å‹ã€‚æ•°æ®é›†é¢„å¤„ç†æŒ‡å—è¯·æŸ¥é˜…[æ–‡æ¡£](./docs/zh_cn/user_guides/dataset_prepare.md)ã€‚

- **æ­¥éª¤ 0**ï¼Œå‡†å¤‡é…ç½®æ–‡ä»¶ã€‚XTuner æä¾›å¤šä¸ªå¼€ç®±å³ç”¨çš„é…ç½®æ–‡ä»¶ï¼Œç”¨æˆ·å¯ä»¥é€šè¿‡ä¸‹åˆ—å‘½ä»¤æŸ¥çœ‹ï¼š

  ```shell
  xtuner list-cfg
  ```

  æˆ–è€…ï¼Œå¦‚æœæ‰€æä¾›çš„é…ç½®æ–‡ä»¶ä¸èƒ½æ»¡è¶³ä½¿ç”¨éœ€æ±‚ï¼Œè¯·å¯¼å‡ºæ‰€æä¾›çš„é…ç½®æ–‡ä»¶å¹¶è¿›è¡Œç›¸åº”æ›´æ”¹ï¼š

  ```shell
  xtuner copy-cfg ${CONFIG_NAME} ${SAVE_PATH}
  ```

- **æ­¥éª¤ 1**ï¼Œå¼€å§‹å¾®è°ƒã€‚

  ```shell
  xtuner train ${CONFIG_NAME_OR_PATH}
  ```

  ä¾‹å¦‚ï¼Œæˆ‘ä»¬å¯ä»¥åˆ©ç”¨ QLoRA ç®—æ³•åœ¨ oasst1 æ•°æ®é›†ä¸Šå¾®è°ƒ InternLM-7Bï¼š

  ```shell
  # å•å¡
  xtuner train internlm_7b_qlora_oasst1_e3
  # å¤šå¡
  NPROC_PER_NODE=${GPU_NUM} xtuner train internlm_7b_qlora_oasst1_e3
  ```

  æ›´å¤šç¤ºä¾‹ï¼Œè¯·æŸ¥é˜…[æ–‡æ¡£](./docs/zh_cn/user_guides/finetune.md)ã€‚

- **æ­¥éª¤ 2**ï¼Œå°†ä¿å­˜çš„ PTH æ¨¡å‹ï¼ˆå¦‚æœä½¿ç”¨çš„DeepSpeedï¼Œåˆ™å°†ä¼šæ˜¯ä¸€ä¸ªæ–‡ä»¶å¤¹ï¼‰è½¬æ¢ä¸º HuggingFace æ¨¡å‹ï¼š

  ```shell
  xtuner convert pth_to_hf ${CONFIG_NAME_OR_PATH} ${PTH} ${SAVE_PATH}
  ```

### å¯¹è¯ [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/drive/144OuTVyT_GvFyDMtlSlTzcxYIfnRsklq?usp=sharing)

XTuner æä¾›ä¸å¤§è¯­è¨€æ¨¡å‹å¯¹è¯çš„å·¥å…·ã€‚

```shell
xtuner chat ${NAME_OR_PATH_TO_LLM} --adapter {NAME_OR_PATH_TO_ADAPTER} [optional arguments]
```

ä¾‹å¦‚ï¼Œä¸ Llama2-7b + MOSS-003-SFT adapter å¯¹è¯ï¼š

```shell
xtuner chat meta-llama/Llama-2-7b-hf --adapter xtuner/Llama-2-7b-qlora-moss-003-sft --bot-name Llama2 --prompt-template moss_sft --with-plugins calculate solve search --command-stop-word "<eoc>" --answer-stop-word "<eom>" --no-streamer
```

æ›´å¤šç¤ºä¾‹ï¼Œè¯·æŸ¥é˜…[æ–‡æ¡£](./docs/zh_cn/user_guides/chat.md)ã€‚

### éƒ¨ç½²

- **æ­¥éª¤ 0**ï¼Œå°† HuggingFace adapter åˆå¹¶åˆ°å¤§è¯­è¨€æ¨¡å‹ï¼š

  ```shell
  xtuner convert merge \
      ${NAME_OR_PATH_TO_LLM} \
      ${NAME_OR_PATH_TO_ADAPTER} \
      ${SAVE_PATH} \
      --max-shard-size 2GB
  ```

- **æ­¥éª¤ 1**ï¼Œä½¿ç”¨ä»»æ„æ¨ç†æ¡†æ¶éƒ¨ç½²å¾®è°ƒåçš„å¤§è¯­è¨€æ¨¡å‹ï¼Œä¾‹å¦‚ [LMDeploy](https://github.com/InternLM/lmdeploy) ğŸš€ï¼š

  ```shell
  pip install lmdeploy
  python -m lmdeploy.pytorch.chat ${NAME_OR_PATH_TO_LLM} \
      --max_new_tokens 256 \
      --temperture 0.8 \
      --top_p 0.95 \
      --seed 0
  ```

  ğŸ”¥ è¿½æ±‚é€Ÿåº¦æ›´å¿«ã€æ˜¾å­˜å ç”¨æ›´ä½çš„æ¨ç†ï¼Ÿæ¬¢è¿ä½“éªŒ [LMDeploy](https://github.com/InternLM/lmdeploy) æä¾›çš„ 4-bit é‡åŒ–ï¼ä½¿ç”¨æŒ‡å—è¯·è§[æ–‡æ¡£](https://github.com/InternLM/lmdeploy/tree/main#quantization)ã€‚

  ğŸ¯ æˆ‘ä»¬æ­£åœ¨ä¸ [LMDeploy](https://github.com/InternLM/lmdeploy) ç´§å¯†åˆä½œï¼Œä»¥å®ç°åŸºäºæ’ä»¶å¯¹è¯çš„éƒ¨ç½²ï¼

### è¯„æµ‹

- æ¨èä½¿ç”¨ä¸€ç«™å¼å¹³å° [OpenCompass](https://github.com/InternLM/opencompass) æ¥è¯„æµ‹å¤§è¯­è¨€æ¨¡å‹ï¼Œå…¶ç›®å‰å·²æ¶µç›– 50+ æ•°æ®é›†çš„çº¦ 30 ä¸‡æ¡é¢˜ç›®ã€‚

## ğŸ¤ è´¡çŒ®æŒ‡å—

æˆ‘ä»¬æ„Ÿè°¢æ‰€æœ‰çš„è´¡çŒ®è€…ä¸ºæ”¹è¿›å’Œæå‡ XTuner æ‰€ä½œå‡ºçš„åŠªåŠ›ã€‚è¯·å‚è€ƒ[è´¡çŒ®æŒ‡å—](.github/CONTRIBUTING.md)æ¥äº†è§£å‚ä¸é¡¹ç›®è´¡çŒ®çš„ç›¸å…³æŒ‡å¼•ã€‚

## ğŸ–ï¸ è‡´è°¢

- [Llama 2](https://github.com/facebookresearch/llama)
- [QLoRA](https://github.com/artidoro/qlora)
- [LMDeploy](https://github.com/InternLM/lmdeploy)

## å¼€æºè®¸å¯è¯

è¯¥é¡¹ç›®é‡‡ç”¨ [Apache License 2.0 å¼€æºè®¸å¯è¯](LICENSE)ã€‚åŒæ—¶ï¼Œè¯·éµå®ˆæ‰€ä½¿ç”¨çš„æ¨¡å‹ä¸æ•°æ®é›†çš„è®¸å¯è¯ã€‚
