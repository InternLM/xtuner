<div align="center">
  <img src="https://github.com/InternLM/lmdeploy/assets/36994684/0cf8d00f-e86b-40ba-9b54-dc8f1bc6c8d8" width="600"/>
  <br /><br />

[![GitHub Repo stars](https://img.shields.io/github/stars/InternLM/xtuner?style=social)](https://github.com/InternLM/xtuner/stargazers)
[![license](https://img.shields.io/github/license/InternLM/xtuner.svg)](https://github.com/InternLM/xtuner/blob/main/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/xtuner)](https://pypi.org/project/xtuner/)
[![Downloads](https://static.pepy.tech/badge/xtuner)](https://pypi.org/project/xtuner/)
[![issue resolution](https://img.shields.io/github/issues-closed-raw/InternLM/xtuner)](https://github.com/InternLM/xtuner/issues)
[![open issues](https://img.shields.io/github/issues-raw/InternLM/xtuner)](https://github.com/InternLM/xtuner/issues)

ğŸ‘‹ åŠ å…¥æˆ‘ä»¬ï¼š[![Static Badge](https://img.shields.io/badge/-grey?style=social&logo=wechat&label=å¾®ä¿¡)](https://cdn.vansin.top/internlm/xtuner.jpg)
[![Static Badge](https://img.shields.io/badge/-grey?style=social&logo=twitter&label=æ¨ç‰¹)](https://twitter.com/intern_lm)
[![Static Badge](https://img.shields.io/badge/-grey?style=social&logo=discord&label=Discord)](https://discord.gg/xa29JuW87d)

ğŸ” æ¢ç´¢æˆ‘ä»¬çš„æ¨¡å‹ï¼š
[![Static Badge](https://img.shields.io/badge/-gery?style=social&label=ğŸ¤—%20Huggingface)](https://huggingface.co/xtuner)
[![Static Badge](https://img.shields.io/badge/-gery?style=social&label=ğŸ¤–%20ModelScope)](https://www.modelscope.cn/organization/xtuner)
[![Static Badge](https://img.shields.io/badge/-gery?style=social&label=ğŸ§°%20OpenXLab)](https://openxlab.org.cn/usercenter/xtuner)
[![Static Badge](https://img.shields.io/badge/-gery?style=social&label=ğŸ§ %20WiseModel)](https://www.wisemodel.cn/organization/xtuner)

[English](README.md) | ç®€ä½“ä¸­æ–‡

</div>

## ğŸš€ Speed Benchmark

- XTuner ä¸ LLaMA-Factory åœ¨ Llama2-7B æ¨¡å‹ä¸Šçš„è®­ç»ƒæ•ˆç‡å¯¹æ¯”

<div align=center>
  <img src="https://github.com/InternLM/xtuner/assets/41630003/9c9dfdf4-1efb-4daf-84bf-7c379ae40b8b" style="width:80%">
</div>

- XTuner ä¸ LLaMA-Factory åœ¨ Llama2-70B æ¨¡å‹ä¸Šçš„è®­ç»ƒæ•ˆç‡å¯¹æ¯”

<div align=center>
  <img src="https://github.com/InternLM/xtuner/assets/41630003/5ba973b8-8885-4b72-b51b-c69fa1583bdd" style="width:80%">
</div>

## ğŸ‰ æ›´æ–°
- **\[2024/07\]** æ”¯æŒ [MiniCPM](xtuner/configs/minicpm/) æ¨¡å‹!
- **\[2024/07\]** æ”¯æŒè®­ç»ƒ [DPO](https://github.com/InternLM/xtuner/tree/main/xtuner/configs/dpo)ï¼Œ [ORPO](https://github.com/InternLM/xtuner/tree/main/xtuner/configs/orpo) è¿˜æœ‰ [Reward Model](https://github.com/InternLM/xtuner/tree/main/xtuner/configs/reward_model) ! å¹¶ä¸”èƒ½å¤Ÿæ”¯æŒæ‰“åŒ…æ•°æ®ä»¥åŠåºåˆ—å¹¶è¡ŒåŠŸèƒ½ï¼ è¯·å‚è€ƒ [æ–‡æ¡£](https://xtuner.readthedocs.io/zh-cn/latest/dpo/overview.html) äº†è§£æ›´å¤šä¿¡æ¯ã€‚
- **\[2024/07\]** æ”¯æŒ [InternLM 2.5](xtuner/configs/internlm/internlm2_5_chat_7b/) æ¨¡å‹!
- **\[2024/06\]** æ”¯æŒ [DeepSeek V2](xtuner/configs/deepseek/deepseek_v2_chat/) models! **è®­ç»ƒé€Ÿåº¦æå‡ä¸€å€ï¼**
- **\[2024/04\]** å¤šæ¨¡æ€å¤§æ¨¡å‹ [LLaVA-Phi-3-mini](https://huggingface.co/xtuner/llava-phi-3-mini-hf) å‘å¸ƒï¼å¿«é€Ÿå¼€å§‹è¯·æŸ¥é˜…æ­¤[æ–‡æ¡£](xtuner/configs/llava/phi3_mini_4k_instruct_clip_vit_large_p14_336)ï¼
- **\[2024/04\]** å¤šæ¨¡æ€å¤§æ¨¡å‹ [LLaVA-Llama-3-8B](https://huggingface.co/xtuner/llava-llama-3-8b) å’Œ [LLaVA-Llama-3-8B-v1.1](https://huggingface.co/xtuner/llava-llama-3-8b-v1_1) å‘å¸ƒï¼å¿«é€Ÿå¼€å§‹è¯·æŸ¥é˜…æ­¤[æ–‡æ¡£](xtuner/configs/llava/llama3_8b_instruct_clip_vit_large_p14_336)ï¼
- **\[2024/04\]** æ”¯æŒ [Llama 3](xtuner/configs/llama) æ¨¡å‹ï¼
- **\[2024/04\]** æ”¯æŒåºåˆ—å¹¶è¡Œè®­ç»ƒç­–ç•¥ä»¥å®ç°è¯­è¨€æ¨¡å‹è¶…é•¿ä¸Šä¸‹æ–‡è®­ç»ƒï¼\[[æ–‡æ¡£](https://github.com/InternLM/xtuner/blob/docs/docs/zh_cn/acceleration/train_extreme_long_sequence.rst)\] \[[é€Ÿåº¦åŸºå‡†](https://github.com/InternLM/xtuner/blob/docs/docs/zh_cn/acceleration/benchmark.rst)\]
- **\[2024/02\]** æ”¯æŒ [Gemma](xtuner/configs/gemma) æ¨¡å‹ï¼
- **\[2024/02\]** æ”¯æŒ [Qwen1.5](xtuner/configs/qwen/qwen1_5) æ¨¡å‹ï¼
- **\[2024/01\]** æ”¯æŒ [InternLM2](xtuner/configs/internlm) æ¨¡å‹ï¼åŒæ—¶ï¼Œæœ€æ–°ç‰ˆçš„å¤šæ¨¡æ€å¤§æ¨¡å‹ [LLaVA-Internlm2-7B](https://huggingface.co/xtuner/llava-internlm2-7b) / [20B](https://huggingface.co/xtuner/llava-internlm2-20b) å‘å¸ƒï¼Œå…¶è¡¨ç°å‡ºå¼ºå¤§çš„æ€§èƒ½ï¼
- **\[2024/01\]** æ”¯æŒ [DeepSeek-MoE](https://huggingface.co/deepseek-ai/deepseek-moe-16b-chat) æ¨¡å‹ï¼20GB æ˜¾å­˜å³å¯å®ç° QLoRA å¾®è°ƒï¼Œ4x80GB å³å¯å®ç°å…¨å‚æ•°å¾®è°ƒã€‚å¿«é€Ÿå¼€å§‹è¯·æŸ¥é˜…ç›¸å…³[é…ç½®æ–‡ä»¶](xtuner/configs/deepseek/)ï¼
- **\[2023/12\]** ğŸ”¥ æ”¯æŒå¤šæ¨¡æ€æ¨¡å‹ VLMï¼ˆ[LLaVA-v1.5](https://github.com/haotian-liu/LLaVA)ï¼‰é¢„è®­ç»ƒå’ŒæŒ‡ä»¤å¾®è°ƒï¼å¿«é€Ÿå¼€å§‹è¯·æŸ¥é˜…æ­¤[æ–‡æ¡£](xtuner/configs/llava/README_zh-CN.md)ï¼
- **\[2023/12\]** ğŸ”¥ æ”¯æŒ [Mixtral 8x7B](https://huggingface.co/mistralai/Mixtral-8x7B-Instruct-v0.1) æ¨¡å‹ï¼å¿«é€Ÿå¼€å§‹è¯·æŸ¥é˜…æ­¤[æ–‡æ¡£](xtuner/configs/mixtral/README.md)ï¼
- **\[2023/11\]** æ”¯æŒ [ChatGLM3-6B](xtuner/configs/chatglm) æ¨¡å‹ï¼
- **\[2023/10\]** æ”¯æŒ [MSAgent-Bench](https://modelscope.cn/datasets/damo/MSAgent-Bench) æ•°æ®é›†ï¼Œå¹¶ä¸”å¾®è°ƒæ‰€å¾—å¤§è¯­è¨€æ¨¡å‹å¯åº”ç”¨è‡³ [Lagent](https://github.com/InternLM/lagent) æ¡†æ¶ï¼
- **\[2023/10\]** ä¼˜åŒ–æ•°æ®å¤„ç†é€»è¾‘ä»¥å…¼å®¹ `system` å­—æ®µï¼Œç›¸å…³ç»†èŠ‚è¯·æŸ¥é˜…[æ–‡æ¡£](docs/zh_cn/user_guides/dataset_format.md)ï¼
- **\[2023/09\]** æ”¯æŒ [InternLM-20B](xtuner/configs/internlm) ç³»åˆ—æ¨¡å‹ï¼
- **\[2023/09\]** æ”¯æŒ [Baichuan2](xtuner/configs/baichuan) ç³»åˆ—æ¨¡å‹ï¼
- **\[2023/08\]** XTuner æ­£å¼å‘å¸ƒï¼ä¼—å¤šå¾®è°ƒæ¨¡å‹å·²ä¸Šä¼ è‡³ [HuggingFace](https://huggingface.co/xtuner)ï¼

## ğŸ“– ä»‹ç»

XTuner æ˜¯ä¸€ä¸ªé«˜æ•ˆã€çµæ´»ã€å…¨èƒ½çš„è½»é‡åŒ–å¤§æ¨¡å‹å¾®è°ƒå·¥å…·åº“ã€‚

**é«˜æ•ˆ**

- æ”¯æŒå¤§è¯­è¨€æ¨¡å‹ LLMã€å¤šæ¨¡æ€å›¾æ–‡æ¨¡å‹ VLM çš„é¢„è®­ç»ƒåŠè½»é‡çº§å¾®è°ƒã€‚XTuner æ”¯æŒåœ¨ 8GB æ˜¾å­˜ä¸‹å¾®è°ƒ 7B æ¨¡å‹ï¼ŒåŒæ—¶ä¹Ÿæ”¯æŒå¤šèŠ‚ç‚¹è·¨è®¾å¤‡å¾®è°ƒæ›´å¤§å°ºåº¦æ¨¡å‹ï¼ˆ70B+ï¼‰ã€‚
- è‡ªåŠ¨åˆ†å‘é«˜æ€§èƒ½ç®—å­ï¼ˆå¦‚ FlashAttentionã€Triton kernels ç­‰ï¼‰ä»¥åŠ é€Ÿè®­ç»ƒååã€‚
- å…¼å®¹ [DeepSpeed](https://github.com/microsoft/DeepSpeed) ğŸš€ï¼Œè½»æ¾åº”ç”¨å„ç§ ZeRO è®­ç»ƒä¼˜åŒ–ç­–ç•¥ã€‚

**çµæ´»**

- æ”¯æŒå¤šç§å¤§è¯­è¨€æ¨¡å‹ï¼ŒåŒ…æ‹¬ä½†ä¸é™äº [InternLM](https://huggingface.co/internlm)ã€[Mixtral-8x7B](https://huggingface.co/mistralai)ã€[Llama 2](https://huggingface.co/meta-llama)ã€[ChatGLM](https://huggingface.co/THUDM)ã€[Qwen](https://huggingface.co/Qwen)ã€[Baichuan](https://huggingface.co/baichuan-inc)ã€‚
- æ”¯æŒå¤šæ¨¡æ€å›¾æ–‡æ¨¡å‹ LLaVA çš„é¢„è®­ç»ƒä¸å¾®è°ƒã€‚åˆ©ç”¨ XTuner è®­å¾—æ¨¡å‹ [LLaVA-InternLM2-20B](https://huggingface.co/xtuner/llava-internlm2-20b) è¡¨ç°ä¼˜å¼‚ã€‚
- ç²¾å¿ƒè®¾è®¡çš„æ•°æ®ç®¡é“ï¼Œå…¼å®¹ä»»æ„æ•°æ®æ ¼å¼ï¼Œå¼€æºæ•°æ®æˆ–è‡ªå®šä¹‰æ•°æ®çš†å¯å¿«é€Ÿä¸Šæ‰‹ã€‚
- æ”¯æŒ [QLoRA](http://arxiv.org/abs/2305.14314)ã€[LoRA](http://arxiv.org/abs/2106.09685)ã€å…¨é‡å‚æ•°å¾®è°ƒç­‰å¤šç§å¾®è°ƒç®—æ³•ï¼Œæ”¯æ’‘ç”¨æˆ·æ ¹æ®å…·ä½“éœ€æ±‚ä½œå‡ºæœ€ä¼˜é€‰æ‹©ã€‚

**å…¨èƒ½**

- æ”¯æŒå¢é‡é¢„è®­ç»ƒã€æŒ‡ä»¤å¾®è°ƒä¸ Agent å¾®è°ƒã€‚
- é¢„å®šä¹‰ä¼—å¤šå¼€æºå¯¹è¯æ¨¡ç‰ˆï¼Œæ”¯æŒä¸å¼€æºæˆ–è®­ç»ƒæ‰€å¾—æ¨¡å‹è¿›è¡Œå¯¹è¯ã€‚
- è®­ç»ƒæ‰€å¾—æ¨¡å‹å¯æ— ç¼æ¥å…¥éƒ¨ç½²å·¥å…·åº“ [LMDeploy](https://github.com/InternLM/lmdeploy)ã€å¤§è§„æ¨¡è¯„æµ‹å·¥å…·åº“ [OpenCompass](https://github.com/open-compass/opencompass) åŠ [VLMEvalKit](https://github.com/open-compass/VLMEvalKit)ã€‚

## ğŸ”¥ æ”¯æŒåˆ—è¡¨

<table>
<tbody>
<tr align="center" valign="middle">
<td>
  <b>æ¨¡å‹</b>
</td>
<td>
  <b>æ•°æ®é›†</b>
</td>
<td>
  <b>æ•°æ®æ ¼å¼</b>
</td>
 <td>
  <b>å¾®è°ƒç®—æ³•</b>
</td>
</tr>
<tr valign="top">
<td align="left" valign="top">
<ul>
  <li><a href="https://huggingface.co/internlm">InternLM 2 / 2.5</a></li>
  <li><a href="https://huggingface.co/meta-llama">Llama 2 / 3</a></li>
  <li><a href="https://huggingface.co/collections/microsoft/phi-3-6626e15e9585a200d2d761e3">Phi-3</a></li>
  <li><a href="https://huggingface.co/THUDM/chatglm2-6b">ChatGLM2</a></li>
  <li><a href="https://huggingface.co/THUDM/chatglm3-6b">ChatGLM3</a></li>
  <li><a href="https://huggingface.co/Qwen/Qwen-7B">Qwen</a></li>
  <li><a href="https://huggingface.co/baichuan-inc/Baichuan2-7B-Base">Baichuan2</a></li>
  <li><a href="https://huggingface.co/mistralai/Mixtral-8x7B-Instruct-v0.1">Mixtral</a></li>
  <li><a href="https://huggingface.co/deepseek-ai/DeepSeek-V2-Chat">DeepSeek V2</a></li>
  <li><a href="https://huggingface.co/google">Gemma</a></li>
  <li><a href="https://huggingface.co/openbmb">MiniCPM</a></li>
  <li>...</li>
</ul>
</td>
<td>
<ul>
  <li><a href="https://modelscope.cn/datasets/damo/MSAgent-Bench">MSAgent-Bench</a></li>
  <li><a href="https://huggingface.co/datasets/fnlp/moss-003-sft-data">MOSS-003-SFT</a> ğŸ”§</li>
  <li><a href="https://huggingface.co/datasets/tatsu-lab/alpaca">Alpaca en</a> / <a href="https://huggingface.co/datasets/silk-road/alpaca-data-gpt4-chinese">zh</a></li>
  <li><a href="https://huggingface.co/datasets/WizardLM/WizardLM_evol_instruct_V2_196k">WizardLM</a></li>
  <li><a href="https://huggingface.co/datasets/timdettmers/openassistant-guanaco">oasst1</a></li>
  <li><a href="https://huggingface.co/datasets/garage-bAInd/Open-Platypus">Open-Platypus</a></li>
  <li><a href="https://huggingface.co/datasets/HuggingFaceH4/CodeAlpaca_20K">Code Alpaca</a></li>
  <li><a href="https://huggingface.co/datasets/burkelibbey/colors">Colorist</a> ğŸ¨</li>
  <li><a href="https://github.com/WangRongsheng/ChatGenTitle">Arxiv GenTitle</a></li>
  <li><a href="https://github.com/LiuHC0428/LAW-GPT">Chinese Law</a></li>
  <li><a href="https://huggingface.co/datasets/Open-Orca/OpenOrca">OpenOrca</a></li>
  <li><a href="https://huggingface.co/datasets/shibing624/medical">Medical Dialogue</a></li>
  <li>...</li>
</ul>
</td>
<td>
<ul>
  <li><a href="docs/zh_cn/user_guides/incremental_pretraining.md">Incremental Pre-training</a> </li>
  <li><a href="docs/zh_cn/user_guides/single_turn_conversation.md">Single-turn Conversation SFT</a> </li>
  <li><a href="docs/zh_cn/user_guides/multi_turn_conversation.md">Multi-turn Conversation SFT</a> </li>
</ul>
</td>
<td>
<ul>
  <li><a href="http://arxiv.org/abs/2305.14314">QLoRA</a></li>
  <li><a href="http://arxiv.org/abs/2106.09685">LoRA</a></li>
  <li>å…¨é‡å‚æ•°å¾®è°ƒ</li>
  <li><a href="https://arxiv.org/abs/2305.18290">DPO</a></li>
  <li><a href="https://arxiv.org/abs/2403.07691">ORPO</a></li>
  <li>Reward Model</a></li>
</ul>
</td>
</tr>
</tbody>
</table>

## ğŸ› ï¸ å¿«é€Ÿä¸Šæ‰‹

### å®‰è£…

- æ¨èä½¿ç”¨ conda å…ˆæ„å»ºä¸€ä¸ª Python-3.10 çš„è™šæ‹Ÿç¯å¢ƒ

  ```bash
  conda create --name xtuner-env python=3.10 -y
  conda activate xtuner-env
  ```

- é€šè¿‡ pip å®‰è£… XTunerï¼š

  ```shell
  pip install -U xtuner
  ```

  äº¦å¯é›†æˆ DeepSpeed å®‰è£…ï¼š

  ```shell
  pip install -U 'xtuner[deepspeed]'
  ```

- ä»æºç å®‰è£… XTunerï¼š

  ```shell
  git clone https://github.com/InternLM/xtuner.git
  cd xtuner
  pip install -e '.[all]'
  ```

### å¾®è°ƒ

XTuner æ”¯æŒå¾®è°ƒå¤§è¯­è¨€æ¨¡å‹ã€‚æ•°æ®é›†é¢„å¤„ç†æŒ‡å—è¯·æŸ¥é˜…[æ–‡æ¡£](./docs/zh_cn/user_guides/dataset_prepare.md)ã€‚

- **æ­¥éª¤ 0**ï¼Œå‡†å¤‡é…ç½®æ–‡ä»¶ã€‚XTuner æä¾›å¤šä¸ªå¼€ç®±å³ç”¨çš„é…ç½®æ–‡ä»¶ï¼Œç”¨æˆ·å¯ä»¥é€šè¿‡ä¸‹åˆ—å‘½ä»¤æŸ¥çœ‹ï¼š

  ```shell
  xtuner list-cfg
  ```

  æˆ–è€…ï¼Œå¦‚æœæ‰€æä¾›çš„é…ç½®æ–‡ä»¶ä¸èƒ½æ»¡è¶³ä½¿ç”¨éœ€æ±‚ï¼Œè¯·å¯¼å‡ºæ‰€æä¾›çš„é…ç½®æ–‡ä»¶å¹¶è¿›è¡Œç›¸åº”æ›´æ”¹ï¼š

  ```shell
  xtuner copy-cfg ${CONFIG_NAME} ${SAVE_PATH}
  vi ${SAVE_PATH}/${CONFIG_NAME}_copy.py
  ```

- **æ­¥éª¤ 1**ï¼Œå¼€å§‹å¾®è°ƒã€‚

  ```shell
  xtuner train ${CONFIG_NAME_OR_PATH}
  ```

  ä¾‹å¦‚ï¼Œæˆ‘ä»¬å¯ä»¥åˆ©ç”¨ QLoRA ç®—æ³•åœ¨ oasst1 æ•°æ®é›†ä¸Šå¾®è°ƒ InternLM2.5-Chat-7Bï¼š

  ```shell
  # å•å¡
  xtuner train internlm2_5_chat_7b_qlora_oasst1_e3 --deepspeed deepspeed_zero2
  # å¤šå¡
  (DIST) NPROC_PER_NODE=${GPU_NUM} xtuner train internlm2_5_chat_7b_qlora_oasst1_e3 --deepspeed deepspeed_zero2
  (SLURM) srun ${SRUN_ARGS} xtuner train internlm2_5_chat_7b_qlora_oasst1_e3 --launcher slurm --deepspeed deepspeed_zero2
  ```

  - `--deepspeed` è¡¨ç¤ºä½¿ç”¨ [DeepSpeed](https://github.com/microsoft/DeepSpeed) ğŸš€ æ¥ä¼˜åŒ–è®­ç»ƒè¿‡ç¨‹ã€‚XTuner å†…ç½®äº†å¤šç§ç­–ç•¥ï¼ŒåŒ…æ‹¬ ZeRO-1ã€ZeRO-2ã€ZeRO-3 ç­‰ã€‚å¦‚æœç”¨æˆ·æœŸæœ›å…³é—­æ­¤åŠŸèƒ½ï¼Œè¯·ç›´æ¥ç§»é™¤æ­¤å‚æ•°ã€‚

  - æ›´å¤šç¤ºä¾‹ï¼Œè¯·æŸ¥é˜…[æ–‡æ¡£](./docs/zh_cn/user_guides/finetune.md)ã€‚

- **æ­¥éª¤ 2**ï¼Œå°†ä¿å­˜çš„ PTH æ¨¡å‹ï¼ˆå¦‚æœä½¿ç”¨çš„DeepSpeedï¼Œåˆ™å°†ä¼šæ˜¯ä¸€ä¸ªæ–‡ä»¶å¤¹ï¼‰è½¬æ¢ä¸º HuggingFace æ¨¡å‹ï¼š

  ```shell
  xtuner convert pth_to_hf ${CONFIG_NAME_OR_PATH} ${PTH} ${SAVE_PATH}
  ```

### å¯¹è¯

XTuner æä¾›ä¸å¤§è¯­è¨€æ¨¡å‹å¯¹è¯çš„å·¥å…·ã€‚

```shell
xtuner chat ${NAME_OR_PATH_TO_LLM} --adapter {NAME_OR_PATH_TO_ADAPTER} [optional arguments]
```

ä¾‹å¦‚ï¼š

ä¸ InternLM2.5-Chat-7B å¯¹è¯ï¼š

```shell
xtuner chat internlm/internlm2-chat-7b --prompt-template internlm2_chat
```

æ›´å¤šç¤ºä¾‹ï¼Œè¯·æŸ¥é˜…[æ–‡æ¡£](./docs/zh_cn/user_guides/chat.md)ã€‚

### éƒ¨ç½²

- **æ­¥éª¤ 0**ï¼Œå°† HuggingFace adapter åˆå¹¶åˆ°å¤§è¯­è¨€æ¨¡å‹ï¼š

  ```shell
  xtuner convert merge \
      ${NAME_OR_PATH_TO_LLM} \
      ${NAME_OR_PATH_TO_ADAPTER} \
      ${SAVE_PATH} \
      --max-shard-size 2GB
  ```

- **æ­¥éª¤ 1**ï¼Œä½¿ç”¨ä»»æ„æ¨ç†æ¡†æ¶éƒ¨ç½²å¾®è°ƒåçš„å¤§è¯­è¨€æ¨¡å‹ï¼Œä¾‹å¦‚ [LMDeploy](https://github.com/InternLM/lmdeploy) ğŸš€ï¼š

  ```shell
  pip install lmdeploy
  python -m lmdeploy.pytorch.chat ${NAME_OR_PATH_TO_LLM} \
      --max_new_tokens 256 \
      --temperture 0.8 \
      --top_p 0.95 \
      --seed 0
  ```

  ğŸ”¥ è¿½æ±‚é€Ÿåº¦æ›´å¿«ã€æ˜¾å­˜å ç”¨æ›´ä½çš„æ¨ç†ï¼Ÿæ¬¢è¿ä½“éªŒ [LMDeploy](https://github.com/InternLM/lmdeploy) æä¾›çš„ 4-bit é‡åŒ–ï¼ä½¿ç”¨æŒ‡å—è¯·è§[æ–‡æ¡£](https://github.com/InternLM/lmdeploy/tree/main#quantization)ã€‚

### è¯„æµ‹

- æ¨èä½¿ç”¨ä¸€ç«™å¼å¹³å° [OpenCompass](https://github.com/InternLM/opencompass) æ¥è¯„æµ‹å¤§è¯­è¨€æ¨¡å‹ï¼Œå…¶ç›®å‰å·²æ¶µç›– 50+ æ•°æ®é›†çš„çº¦ 30 ä¸‡æ¡é¢˜ç›®ã€‚

## ğŸ¤ è´¡çŒ®æŒ‡å—

æˆ‘ä»¬æ„Ÿè°¢æ‰€æœ‰çš„è´¡çŒ®è€…ä¸ºæ”¹è¿›å’Œæå‡ XTuner æ‰€ä½œå‡ºçš„åŠªåŠ›ã€‚è¯·å‚è€ƒ[è´¡çŒ®æŒ‡å—](.github/CONTRIBUTING.md)æ¥äº†è§£å‚ä¸é¡¹ç›®è´¡çŒ®çš„ç›¸å…³æŒ‡å¼•ã€‚

## ğŸ–ï¸ è‡´è°¢

- [Llama 2](https://github.com/facebookresearch/llama)
- [DeepSpeed](https://github.com/microsoft/DeepSpeed)
- [QLoRA](https://github.com/artidoro/qlora)
- [LMDeploy](https://github.com/InternLM/lmdeploy)
- [LLaVA](https://github.com/haotian-liu/LLaVA)

## ğŸ–Šï¸ å¼•ç”¨

```bibtex
@misc{2023xtuner,
    title={XTuner: A Toolkit for Efficiently Fine-tuning LLM},
    author={XTuner Contributors},
    howpublished = {\url{https://github.com/InternLM/xtuner}},
    year={2023}
}
```

## å¼€æºè®¸å¯è¯

è¯¥é¡¹ç›®é‡‡ç”¨ [Apache License 2.0 å¼€æºè®¸å¯è¯](LICENSE)ã€‚åŒæ—¶ï¼Œè¯·éµå®ˆæ‰€ä½¿ç”¨çš„æ¨¡å‹ä¸æ•°æ®é›†çš„è®¸å¯è¯ã€‚
