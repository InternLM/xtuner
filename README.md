# MMChat

## Highlights

### Supported Models, Datasets, and Strategies

<table>
<tbody>
<tr align="left" valign="middle">
<td>
  <b>Models</b>
</td>
<td>
  <b>Datasets</b>
</td>
<td>
  <b>Strategies</b>
</td>
</tr>
<tr valign="top">
<td align="left" valign="top">
<ul>
  <li><a href="">InternLM</a></li>
  <li><a href="">InternLM-Chat</a></li>
  <li><a href="">Llama</a></li>
  <li><a href="">Llama2</a></li>
  <li><a href="">Llama2-Chat</a></li>
  <li><a href="">Qwen</a></li>
  <li><a href="">Qwen-Chat</a></li>
  <li><a href="">Baichuan-7B</a></li>
  <li><a href="">Baichuan-13B-Base</a></li>
  <li><a href="">Baichuan-13B-Chat</a></li>
  <li>...</li>    
</ul>
</td>
<td>
<ul>
  <li><a href="">MOSS-003-SFT</a></li>
  <li><a href="">Alpaca en/zh</a></li>
  <li><a href="">oasst1</a></li>
  <li><a href="">Arxiv GenTitle</a></li>
  <li><a href="">Chinese Medical Dialogue</a></li>
  <li>...</li>  
</ul>
</td>
<td>
<ul>
  <li><a href="">Normal (Distributed) Data Parallel</a></li>
  <li><a href="">Deepspeed</a></li>
  <li>...</li>  
</ul>
</td>
</tr>
</tbody>
</table>

### Chat with Plugins

Calculate, Equations Solve, Web Search, ...

### Colab Demos

### Minimum System Requirements





## Quick Start

### Installation

1. Install PyTorch following [official instructions](https://pytorch.org/get-started/locally/), e.g.

```shell
conda install pytorch torchvision torchaudio pytorch-cuda=11.7 -c pytorch -c nvidia
```

2. Install dependencies and XXX

```shell
git clone XXX
cd XXX
pip install -v -e .
```

### Finetune

We support the Full / LoRA / QLoRA finetune for Large Language Models (LLM). 



### Chat

### Deploy

## Performance

## Roadmap

## Acknowledgement

## License

