.. _xtuner_rlhf_arch:

系统架构
-------------

XTuner-RLHF 模块的架构如图所示：

.. image:: images/arch.svg
   :alt: XTuner RLHF 架构

引擎层
~~~~~~~~~~~~~

引擎层对训练、推理和生成进行了解耦，支持用户选用不同的引擎进行训练、推理和生成，比如可选用 transformers 进行训练和推理，选用 vLLM 进行生成。多引擎设计的优点在于：

**灵活性和适应性**：不同的项目可能有不同的需求和限制。集成多个框架可以让用户根据具体情况选择最合适的工具，提升开发效率和效果。

**性能优化**：不同框架在不同类型的任务上可能有不同的性能表现。用户可以选择在特定任务上表现最优的框架，以达到最佳性能。

**跨平台兼容性**：某些框架在特定平台上表现更好，或仅支持特定的硬件。提供多个框架选择可以确保在不同平台和硬件上的兼容性和优化。

**易用性**：一些框架可能更加用户友好，适合快速原型开发；而另一些框架可能更适合大规模部署。用户可以根据开发阶段选择合适的框架。

调度层
~~~~~~~~~~~~~

中间的调度层向上层算法提供模型级别操作接口，简化与底层引擎的交互，同时向下适配不同的训练框架和模型，负责多模型资源的统筹和调度，确保系统高效运行。

算法层
~~~~~~~~~~~~~

算法层实现不同的强化学习算法和环境，即具体的训练策略和应用场景。包括 PPO、DPO 等各种强化学习算法，以及 Q&A（问答）、LR（逻辑推理）等不同的任务环境。

Ray
~~~~~~~~~~~~~

XTuner-RLHF 集成了 Ray 来进行分布式训练、推理和生成，提供了高效的资源管理和任务调度功能：

**对底层集群和硬件的屏蔽**：Ray 提供了一层抽象，使用户无需关注底层硬件的细节。无论是本地集群还是云端资源，Ray 都能统一管理和调度任务，从而简化开发和部署流程。

**高效的资源管理**：可以动态调整计算资源的分配，根据任务的需求灵活调度 CPU、GPU 等资源，确保高效利用计算资源，提升系统整体性能。

**自动化故障恢复**：Ray 内置了容错机制，能够自动检测和恢复失败的任务，保证系统的稳定性和可靠性，减少人为干预的需要。

**扩展性强**：可以方便地扩展到大规模集群，支持数百乃至数千个节点。这使得系统可以根据需求进行水平扩展，满足大规模数据处理和计算的需求。

**灵活的任务调度**：可以根据任务的优先级和资源需求进行灵活调度，优化任务执行顺序，减少任务的等待时间，提高系统吞吐量。