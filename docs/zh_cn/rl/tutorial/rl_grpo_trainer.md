```{important}
XTuner çš„ RLï¼ˆå¼ºåŒ–å­¦ä¹ ï¼‰åŠŸèƒ½ç›®å‰ä¸º Beta ç‰ˆæœ¬ï¼ŒRLåŠŸèƒ½ç‰¹æ€§æŒç»­å®Œå–„ä¸­ï¼Œæ¬¢è¿è¯•ç”¨å¹¶åé¦ˆé—®é¢˜ã€‚
```



# [Beta] ä½¿ç”¨ Python ä»£ç è‡ªå®šä¹‰ GRPO è®­ç»ƒ




åœ¨ä¹‹å‰çš„[æ•™ç¨‹](../../get_started/grpo.md)ä¸­ï¼Œæˆ‘ä»¬å·²ç»é€šè¿‡å‘½ä»¤è¡Œä½“éªŒäº†å¿«é€Ÿå¯åŠ¨ GRPO å¼ºåŒ–å­¦ä¹ è®­ç»ƒã€‚æœ¬æ•™ç¨‹å°†ä»‹ç»å¦‚ä½•é€šè¿‡ Python ä»£ç è‡ªå®šä¹‰ GRPO è®­ç»ƒé…ç½®ï¼Œè®©æ‚¨èƒ½å¤Ÿæ›´çµæ´»åœ°æ§åˆ¶è®­ç»ƒå‚æ•°ã€‚

GRPO è®­ç»ƒä¸»è¦åŒ…å«ä¸¤å¤§é…ç½®æ¨¡å—ï¼š**Generation Configï¼ˆç”Ÿæˆé…ç½®ï¼‰** å’Œ **Trainer Configï¼ˆè®­ç»ƒé…ç½®ï¼‰**ã€‚

## 1. Generation Configï¼ˆç”Ÿæˆé…ç½®ï¼‰

åœ¨å¼ºåŒ–å­¦ä¹ è®­ç»ƒä¸­ï¼Œæ•°æ®ç”Ÿæˆæ˜¯ä¸€ä¸ªå…³é”®ç¯èŠ‚ï¼Œé€šå¸¸åŒ…å«**é‡‡æ · â†’ æ¨ç† â†’ è¿‡æ»¤**ä¸‰ä¸ªæ­¥éª¤ã€‚åœ¨æ¨ç†é˜¶æ®µï¼Œæˆ‘ä»¬ä½¿ç”¨é«˜æ•ˆçš„æ¨ç†å¼•æ“ï¼ˆå¦‚ LMDeployï¼‰æ¥ç”Ÿæˆæ¨¡å‹å“åº”ã€‚æœ¬èŠ‚å°†ä»‹ç»æ•°æ®ç”Ÿæˆç›¸å…³çš„å„é¡¹é…ç½®ï¼Œå¸®åŠ©æ‚¨æŒæ§æ•´ä¸ªç”Ÿæˆæµç¨‹ã€‚

### 1.1 DataFlowConfig

`DataFlow` æ˜¯è®­ç»ƒæ•°æ®ç”Ÿæˆçš„æ ¸å¿ƒæ§åˆ¶å™¨ï¼Œè´Ÿè´£åè°ƒæ•´ä¸ªç”Ÿæˆæµç¨‹ã€‚

å¯¹äºGRPOç®—æ³•æ¥è¯´ï¼Œåœ¨`DataFlowConfig`ä¸­ï¼Œæ‚¨éœ€è¦ä¿®æ”¹çš„å…³é”®å‚æ•°å¦‚ä¸‹ï¼š
- `prompt_repeat_k`ï¼šæ¯ä¸ª prompt çš„é‡å¤é‡‡æ ·æ¬¡æ•°
- `global_batch_size`ï¼šæ¯è½® Rollout çš„å…¨å±€æ‰¹æ¬¡å¤§å°  

```{tip}
:class: margin

æ›´å¤šé…ç½®å‚æ•°è¯·å‚è€ƒAPIæ–‡æ¡£ï¼š{class}`~xtuner.v1.ray.dataflow.DataFlowConfig`
```

```{code-block} python
:caption: é…ç½®æ•°æ®æµ
from xtuner.v1.ray.dataflow import DataFlowConfig

dataflow_config = DataFlowConfig(
    prompt_repeat_k=5,
    global_batch_size=1024
)
```


### 1.2 ReplayBufferConfig

ç»éªŒå›æ”¾æ± ï¼ˆ`Replay Buffer`ï¼‰å°±åƒä¸€ä¸ª"æ•°æ®ä»“åº“"ï¼Œå®ƒçš„å·¥ä½œå¾ˆç®€å•ï¼š**é‡‡æ ·æ•°æ®ã€å­˜å‚¨æ•°æ®ã€æŒ‰ç…§ä¸€å®šè§„åˆ™æä¾›æ•°æ®**ã€‚åœ¨å¼ºåŒ–å­¦ä¹ ä¸­ï¼Œæ¨¡å‹ç”Ÿæˆçš„æ ·æœ¬ä¼šå…ˆå­˜åˆ°è¿™ä¸ª"ä»“åº“"é‡Œï¼Œç„¶åè®­ç»ƒæ—¶å†ä»è¿™é‡Œå–å‡ºæ•°æ®æ¥è®­ç»ƒæ¨¡å‹ã€‚

**å¯¹äºå¤§å¤šæ•°ç”¨æˆ·æ¥è¯´ï¼Œæ‚¨åªéœ€è¦ä¿®æ”¹`ReplayBufferConfig`ä¸­å››ä¸ªå…³é”®å‚æ•°å°±èƒ½æ­£å¸¸ä½¿ç”¨**ï¼š
- `model_path`ï¼šæ¨¡å‹è·¯å¾„
- `train_data_path`ï¼šè®­ç»ƒæ•°æ®è·¯å¾„  
- `max_prompt_length`ï¼šè¾“å…¥æ–‡æœ¬çš„æœ€å¤§é•¿åº¦
- `pack_max_length`ï¼šè®­ç»ƒæ•°æ®æ‰“åŒ…çš„æœ€å¤§é•¿åº¦

```{code-block} python
:caption: é…ç½®ç»éªŒå›æ”¾æ± 
from transformers import AutoTokenizer
from xtuner.v1.config import DatasetConfig, DataloaderConfig
from xtuner.v1.ray.dataflow import ReplayBufferConfig
from xtuner.v1.datasets import RLTextTokenizeFnConfig

train_data_path = "./gsm8k/train.jsonl"    # è®­ç»ƒæ•°æ®è·¯å¾„
model_path = "/path/to/qwen3-8B"           # æ¨¡å‹è·¯å¾„
max_prompt_length = 512                    # è¾“å…¥æœ€å¤§é•¿åº¦
pack_max_length = 32768                    # æ‰“åŒ…æœ€å¤§é•¿åº¦

replay_buffer_cfg = ReplayBufferConfig(
    dataset_cfg=[{
        "dataset": DatasetConfig(name="gsm8k", anno_path=train_data_path),
        "tokenize_fn": RLTextTokenizeFnConfig(max_length=max_prompt_length),
    }],
    dataloader_cfg=DataloaderConfig(
        pack_max_length=pack_max_length,             
        collator='fake_collator',           
        pack_level='none',                 
    ),
    tokenizer=AutoTokenizer.from_pretrained(model_path, trust_remote_code=True),
)
```

### 1.3 RolloutConfig

`RolloutConfig` è´Ÿè´£é…ç½®æ¨¡å‹æ¨ç†ç¯å¢ƒï¼Œå®ƒå†³å®šäº†å¦‚ä½•ä½¿ç”¨æ¨¡å‹æ¥ç”Ÿæˆè®­ç»ƒæ‰€éœ€çš„æ ·æœ¬æ•°æ®ã€‚å¯ä»¥æŠŠå®ƒç†è§£ä¸º"æ¨ç†å¼•æ“çš„é…ç½®æ–‡ä»¶"ã€‚

åœ¨æœ¬ç¤ºä¾‹ä¸­ï¼Œæ‚¨åªéœ€è¦æŒ‡å®šæ¨¡å‹è·¯å¾„å³å¯å¼€å§‹ä½¿ç”¨ã€‚å…¶ä»–ä½¿ç”¨é»˜è®¤é…ç½®ã€‚

```{tip}
:class: margin

å¦‚æœæ‚¨éœ€è¦æ›´ç²¾ç»†çš„æ§åˆ¶ï¼ˆå¦‚åˆ†å¸ƒå¼æ¨ç†ã€æ¨ç†ä¼˜åŒ–é€‰é¡¹ç­‰ï¼‰ï¼Œå¯ä»¥å‚è€ƒAPIæ–‡æ¡£ï¼š{class}`~xtuner.v1.ray.config.worker.RolloutConfig`
```

```{code-block} python
:caption: é…ç½®æ¨ç†ç¯å¢ƒ
from xtuner.v1.ray.config.worker import RolloutConfig

model_path = "/path/to/qwen3-8B"  # æ›¿æ¢ä¸ºæ‚¨çš„æ¨¡å‹è·¯å¾„

rollout_config = RolloutConfig(
    model_path=model_path,           # æ¨ç†æ¨¡å‹è·¯å¾„
    model_name="qwen3-8B",           # æ¨¡å‹åç§°
    tokenizer_path=model_path,       # åˆ†è¯å™¨è·¯å¾„
)
```


### 1.4 JudgerConfig

XTuner ä¸ºGSM8Kæä¾›äº†ç°æˆçš„åˆ¤æ–­å™¨ã€‚æ‚¨å¯ä»¥ç›´æ¥ä½¿ç”¨ç¤ºä¾‹ä»£ç ã€‚

```{code-block} python
:caption: é…ç½®å¥–åŠ±æ¨¡å‹
from xtuner.v1.ray.judger.controller import JudgerConfig
from xtuner.v1.ray.judger.gsm8k import GSM8KJudgerConfig

judger_cfg = JudgerConfig(
    reward_judger_configs={
        "openai/gsm8k": GSM8KJudgerConfig()  # GSM8Kæ•°å­¦é¢˜åˆ¤æ–­å™¨
    }
)
```

**ä½¿ç”¨è¯´æ˜**ï¼š
- `"openai/gsm8k"`ï¼šæ•°æ®é›†æ ‡è¯†ç¬¦ï¼Œéœ€è¦ä¸æ‚¨æ•°æ®é›†ä¸­çš„ `data_source` å­—æ®µåŒ¹é…
- `GSM8KJudgerConfig()`ï¼šä¸“é—¨ç”¨äº GSM8K æ•°å­¦é¢˜çš„åˆ¤æ–­å™¨ï¼Œä¼šæ£€æŸ¥ç­”æ¡ˆçš„æ•°å€¼æ˜¯å¦æ­£ç¡®

ğŸ’¡ **æ‰©å±•åŠŸèƒ½**ï¼šXTuner è¿˜æ”¯æŒå¤šç§åˆ¤æ–­æ–¹å¼ï¼ˆå‡½æ•°å¼ã€APIæœåŠ¡å¼ï¼‰å’Œè‡ªå®šä¹‰Judgerï¼Œç›¸å…³æ•™ç¨‹å³å°†æ¨å‡ºã€‚

## 2. Trainer Configï¼ˆè®­ç»ƒé…ç½®ï¼‰

### 2.1 WorkerConfig

`WorkerConfig` æ˜¯è®­ç»ƒé˜¶æ®µçš„æ ¸å¿ƒï¼Œå®ƒæ§åˆ¶ç€æ¨¡å‹å¦‚ä½•å­¦ä¹ å’Œä¼˜åŒ–ã€‚è¿™é‡ŒåŒ…å«äº†æ¨¡å‹ç»“æ„ã€ä¼˜åŒ–å™¨ã€æŸå¤±å‡½æ•°ç­‰æ‰€æœ‰è®­ç»ƒç›¸å…³çš„æ ¸å¿ƒé…ç½®ã€‚

å¯¹äº Qwen3-8B æ¨¡å‹ï¼Œæˆ‘ä»¬å·²ç»ä¸ºæ‚¨å‡†å¤‡äº†æœ€ä½³å®è·µé…ç½®ã€‚å¤§å¤šæ•°æƒ…å†µä¸‹ï¼Œæ‚¨åªéœ€è¦æŒ‡å®šæ¨¡å‹è·¯å¾„ã€è®­ç»ƒä¼˜åŒ–æ­¥æ•°ã€è®­ç»ƒæ•°æ®æ‰“åŒ…é•¿åº¦ç­‰åŸºæœ¬å‚æ•°ï¼š

```{tip}
:class: margin

æ›´å¤šé…ç½®å‚æ•°è¯·å‚è€ƒAPIæ–‡æ¡£ï¼š{class}`~xtuner.v1.rl.base.worker.WorkerConfig`
```

```{code-block} python
:caption: é…ç½®è®­ç»ƒç­–ç•¥
from xtuner.v1.config import AdamWConfig, FSDPConfig, LRConfig
from xtuner.v1.model.dense.qwen3 import Qwen3Dense8BConfig
from xtuner.v1.rl.base import WorkerConfig
from xtuner.v1.rl.grpo import GRPOLossConfig

model_path = "/path/to/qwen3-8B"        # å¡«å…¥æ‚¨çš„æ¨¡å‹è·¯å¾„
train_optimizer_steps = 4               # è®­ç»ƒä¼˜åŒ–æ­¥æ•°
pack_max_length = 32768                 # æ•°æ®æ‰“åŒ…æœ€å¤§é•¿åº¦

train_worker_cfg = WorkerConfig(
    model_cfg=Qwen3Dense8BConfig(),                    # ä½¿ç”¨é¢„è®¾çš„ Qwen3-8B é…ç½®
    optim_cfg=AdamWConfig(lr=1e-6, foreach=False),    # ä¼˜åŒ–å™¨ï¼šå­¦ä¹ ç‡ 1e-6
    loss_cfg=GRPOLossConfig(                          # GRPO æŸå¤±å‡½æ•°é…ç½®
        policy_loss_cfg=dict(
            cliprange_high=0.2,     # ç­–ç•¥æ¢¯åº¦è£å‰ªä¸Šé™
            cliprange_low=0.2,      # ç­–ç•¥æ¢¯åº¦è£å‰ªä¸‹é™
            loss_type="vanilla",    # æŸå¤±ç±»å‹
        ),
        ignore_idx=-100,            # å¿½ç•¥çš„ token ç´¢å¼•
        use_kl_loss=True,           # å¯ç”¨ KL æ•£åº¦æŸå¤±
        kl_loss_coef=0.001,         # KL æŸå¤±ç³»æ•°
        kl_loss_type="low_var_kl",  # KL æŸå¤±ç±»å‹
        mode="chunk",               # è®¡ç®—æ¨¡å¼
        chunk_size=512              # åˆ†å—å¤§å°
    ),
    lr_cfg=LRConfig(warmup_ratio=0),       # å­¦ä¹ ç‡ç­–ç•¥ï¼šæ— é¢„çƒ­
    fsdp_cfg=FSDPConfig(),                 # åˆ†å¸ƒå¼è®­ç»ƒé…ç½®
    load_from=model_path,                  # åŠ è½½æ¨¡å‹è·¯å¾„
    optimizer_steps=train_optimizer_steps, # ä¼˜åŒ–æ­¥æ•°
    pack_max_length=pack_max_length,       # åºåˆ—æœ€å¤§é•¿åº¦
)
```


### 2.2 EvaluatorConfig [å¯é€‰]

å¦‚æœæ‚¨éœ€è¦åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­è¿›è¡ŒéªŒè¯ï¼Œå¯ä»¥é…ç½® `EvaluatorConfig`ã€‚å®ƒå®šä¹‰äº†éªŒè¯æ•°æ®é›†ã€éªŒè¯é¢‘ç‡ç­‰ã€‚
åœ¨æœ¬ç¤ºä¾‹ä¸­ï¼Œæ‚¨ä»…éœ€è¦ä¿®æ”¹eval_data_pathå’Œevaluate_stepé—´éš”å³å¯ã€‚

```{code-block} python
:caption: é…ç½®éªŒè¯æµç¨‹
from xtuner.v1.ray.evaluator import EvaluatorConfig

eval_data_path = "./gsm8k/test.jsonl"
eval_dataset_cfg = [{"dataset": DatasetConfig(name="gsm8k", anno_path=eval_data_path)}]
evaluator_cfg = EvaluatorConfig(
    dataset_cfg=eval_dataset_cfg,
    tokenizer=tokenizer,
    evaluate_step=10, # æ¯è®­ç»ƒ10ä¸ªepochéªŒè¯ä¸€æ¬¡
)
```

## 3ã€æ„å»ºå¹¶å¯åŠ¨ RLTrainer

### 3.1 AcceleratorResourcesConfig

é™¤ä»¥ä¸Šçš„ç”Ÿæˆå’Œè®­ç»ƒé…ç½®å¤–ï¼Œæˆ‘ä»¬éœ€è¦é…ç½®ç³»ç»Ÿæ‰€éœ€èµ„æºï¼ˆå¦‚GPUã€CPUã€å†…å­˜ï¼‰ç­‰ï¼Œæ­¤å¤„æˆ‘ä»¬ä½¿ç”¨é»˜è®¤çš„èµ„æºé…ç½®ï¼Œç¤ºä¾‹å¦‚ä¸‹ã€‚

```{code-block} python
from xtuner.v1.ray.accelerator import AcceleratorResourcesConfig
resources = AcceleratorResourcesConfig(
    accelerator="GPU",
    num_accelerators_per_worker=1,
    num_cpus_per_worker=12,
    num_workers=8,
    cpu_memory_per_worker=16 * 1024**3, 
)
```

### 3.2 ç»„è£… RLTrainer
å®Œæˆæ‰€æœ‰ç»„ä»¶çš„é…ç½®åï¼Œæˆ‘ä»¬å°±å¯ä»¥å°†å®ƒä»¬ç»„è£…è¿› `RLTrainer`ï¼Œå¹¶å¯åŠ¨è®­ç»ƒæµç¨‹ã€‚

```{code-block} python
:caption: æ„å»ºå¹¶å¯åŠ¨ RLTrainer
import ray
from xtuner.v1.train.rl_trainer import RLTrainer

# åˆå§‹åŒ– Ray
ray.init(num_cpus=128, ignore_reinit_error=True)

# ä¿®æ”¹è·¯å¾„
model_path = "/path/to/qwen3-8B"
train_data_path = "./gsm8k/train.jsonl"
eval_data_path = "./gsm8k/test.jsonl"
work_dir = "work_dirs/grpo_py_train"

# é…ç½®å‚æ•°
prompt_repeat_k = 5
global_batch_size = 1024
max_prompt_length = 512
pack_max_length = 32768
train_optimizer_steps = 4

# å£°æ˜ä¸Šè¿°æ‰€æœ‰config
# ...

# ç»„è£…RLTrainer
trainer = RLTrainer(
    resources=resources,
    rollout_config=rollout_config,
    dataflow_config=dataflow_config,
    judger_config=judger_cfg,
    replay_buffer_config=replay_buffer_cfg,
    evaluator_config=evaluator_cfg,
    train_worker_cfg=train_worker_cfg,
    tokenizer_path=model_path,
    work_dir=work_dir,
    total_epochs=15,
    enable_evaluate=False
)
# å¼€å§‹è®­ç»ƒ
trainer.fit()
```

## 4ã€ç»“è¯­

å°†ä»¥ä¸Šæ‰€æœ‰é…ç½®ç»„åˆå¹¶ä¿å­˜ä¸º Python æ–‡ä»¶ï¼ˆä¾‹å¦‚ `train_grpo.py`ï¼‰ï¼Œå³å¯é€šè¿‡ä»¥ä¸‹å‘½ä»¤å¯åŠ¨è®­ç»ƒï¼š

```bash
XTUNER_USE_FA3=1 XTUNER_USE_LMDEPLOY=1 python train_grpo.py
```

æ­å–œä½ ï¼ç°åœ¨ä½ å·²ç»æŒæ¡äº†é€šè¿‡ Python ä»£ç è‡ªå®šä¹‰ `RLTrainer` çš„æ–¹æ³•ï¼Œå¯ä»¥æ›´çµæ´»åœ°è¿›è¡Œå¼ºåŒ–å­¦ä¹ å®éªŒäº†ã€‚