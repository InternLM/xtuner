# LLaVA å…¨æµç¨‹

[English](./README.md) | ç®€ä½“ä¸­æ–‡

## ç»“æœ

XTuner æ¨èä½¿ç”¨åŸºäº LLM-QLoRA / ViT-LoRA çš„ LLaVA æ¶æ„ï¼Œå…¶åœ¨å„ä¸ªæ•°æ®é›†çš„è¯„æµ‹ç»“æœå¦‚ä¸‹ï¼š

| æ¨¡å‹                         | MMBench Test (EN) | MMBench Dev (EN) | MMBench Test (CN) | MMBench Dev (CN) | CCBench Dev | MME  | SEEDBench_IMG | MMVet | MMMU Dev | MathVista MiniTest | HallusionBench aAcc |                                                                                                                                        é…ç½®æ–‡ä»¶                                                                                                                                         | é¢„è®­ç»ƒ Projector æƒé‡                                                                                                                                                |                                                                  å¾®è°ƒ LLaVA æƒé‡                                                                   |
| :--------------------------- | :---------------: | :--------------: | :---------------: | :--------------: | :---------: | :--: | :-----------: | :---: | :------: | :----------------: | :-----------------: | :-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------: | -------------------------------------------------------------------------------------------------------------------------------------------------------------------- | :------------------------------------------------------------------------------------------------------------------------------------------------: |
| LLaVA-v1.5-7B (XTuner)       |       67.7        |       69.2       |       61.0        |       59.7       |    28.4     | 1716 |     66.4      | 32.2  |   33.7   |        24.2        |        46.2         |           [Pretrain](./vicuna_7b_v15_clip_vit_large_p14_336/pretrain/llava_vicuna_7b_v15_clip_vit_large_p14_336_e1_gpu8_pretrain.py) / [Fine-tune](./vicuna_7b_v15_clip_vit_large_p14_336/finetune/llava_vicuna_7b_v15_qlora_clip_vit_large_p14_336_lora_e1_gpu8_finetune.py)           | ğŸ¤— [HuggingFace](https://huggingface.co/xtuner/llava-v1.5-7b-xtuner-pretrain) / ğŸ¤– [ModelScope](https://modelscope.cn/models/xtuner/llava-v1.5-7b-xtuner-pretrain)   |  ğŸ¤— [HuggingFace](https://huggingface.co/xtuner/llava-v1.5-7b-xtuner) / ğŸ¤– [ModelScope](https://modelscope.cn/models/xtuner/llava-v1.5-7b-xtuner)  |
| LLaVA-v1.5-13B (XTuner)      |       68.8        |       69.5       |       64.7        |       63.1       |    32.9     | 1766 |     67.9      | 35.9  |   35.2   |        26.2        |        46.9         |         [Pretrain](./vicuna_13b_v15_clip_vit_large_p14_336/pretrain/llava_vicuna_13b_v15_clip_vit_large_p14_336_e1_gpu8_pretrain.py) / [Fine-tune](./vicuna_13b_v15_clip_vit_large_p14_336/finetune/llava_vicuna_13b_v15_qlora_clip_vit_large_p14_336_lora_e1_gpu8_finetune.py)         | ğŸ¤— [HuggingFace](https://huggingface.co/xtuner/llava-v1.5-13b-xtuner-pretrain) / ğŸ¤– [ModelScope](https://modelscope.cn/models/xtuner/llava-v1.5-13b-xtuner-pretrain) | ğŸ¤— [HuggingFace](https://huggingface.co/xtuner/llava-v1.5-13b-xtuner) / ğŸ¤– [ModelScope](https://modelscope.cn/models/xtuner/llava-v1.5-13b-xtuner) |
| LLaVA-InternLM-7B (XTuner)   |       69.0        |       68.5       |       66.7        |       63.8       |    37.3     | 1637 |     65.7      | 32.4  |   36.9   |        26.3        |        49.1         |     [Pretrain](./internlm_chat_7b_clip_vit_large_p14_336/pretrain/llava_internlm_chat_7b_clip_vit_large_p14_336_e1_gpu8_pretrain.py) / [Fine-tune](./internlm_chat_7b_clip_vit_large_p14_336/finetune/llava_internlm_chat_7b_qlora_clip_vit_large_p14_336_lora_e1_gpu8_finetune.py)     | ğŸ¤— [HuggingFace](https://huggingface.co/xtuner/llava-internlm-7b-pretrain) / ğŸ¤– [ModelScope](https://modelscope.cn/models/xtuner/llava-internlm-7b-pretrain)         |     ğŸ¤— [HuggingFace](https://huggingface.co/xtuner/llava-internlm-7b) / ğŸ¤– [ModelScope](https://modelscope.cn/models/xtuner/llava-internlm-7b)     |
| LLaVA-InternLM2-7B (XTuner)  |       73.3        |       74.6       |       71.7        |       72.0       |    42.5     | 1700 |     71.2      | 35.9  |   40.1   |        25.5        |        46.8         |   [Pretrain](./internlm2_chat_7b_clip_vit_large_p14_336/pretrain/llava_internlm2_chat_7b_clip_vit_large_p14_336_e1_gpu8_pretrain.py) / [Fine-tune](./internlm2_chat_7b_clip_vit_large_p14_336/finetune/llava_internlm2_chat_7b_qlora_clip_vit_large_p14_336_lora_e1_gpu8_finetune.py)   | ğŸ¤— [HuggingFace](https://huggingface.co/xtuner/llava-internlm2-7b-pretrain) / ğŸ¤– [ModelScope](https://modelscope.cn/models/xtuner/llava-internlm2-7b-pretrain)       |    ğŸ¤— [HuggingFace](https://huggingface.co/xtuner/llava-internlm2-7b) / ğŸ¤– [ModelScope](https://modelscope.cn/models/xtuner/llava-internlm2-7b)    |
| LLaVA-InternLM2-20B (XTuner) |       75.1        |       73.5       |       73.7        |       72.8       |    46.3     | 1868 |     70.2      | 37.2  |   39.4   |        24.6        |        47.7         | [Pretrain](./internlm2_chat_20b_clip_vit_large_p14_336/pretrain/llava_internlm2_chat_20b_clip_vit_large_p14_336_e1_gpu8_pretrain.py) / [Fine-tune](./internlm2_chat_20b_clip_vit_large_p14_336/finetune/llava_internlm2_chat_20b_qlora_clip_vit_large_p14_336_lora_e1_gpu8_finetune.py) | ğŸ¤— [HuggingFace](https://huggingface.co/xtuner/llava-internlm2-20b-pretrain) / ğŸ¤– [ModelScope](https://modelscope.cn/models/xtuner/llava-internlm2-20b-pretrain)     |   ğŸ¤— [HuggingFace](https://huggingface.co/xtuner/llava-internlm2-20b) / ğŸ¤– [ModelScope](https://modelscope.cn/models/xtuner/llava-internlm2-20b)   |

å½“ä¸ LLaVA å®˜æ–¹è®­ç»ƒæ¶æ„å¯¹é½æ—¶ï¼Œå…¶è¯„æµ‹ç»“æœå¦‚ä¸‹ï¼š

| æ¨¡å‹          |   æ¡†æ¶   | MMBench Test (EN) | MMBench Dev (EN) | MMBench Test (CN) | MMBench Dev (CN) | CCBench Dev | MME  | SEEDBench_IMG | MMVet |                                                                                                                         é…ç½®æ–‡ä»¶                                                                                                                         |
| :------------ | :------: | :---------------: | :--------------: | :---------------: | :--------------: | :---------: | :--: | :-----------: | :---: | :------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------: |
| LLaVA-v1.5-7B | Official |       65.2        |       63.0       |       57.3        |       57.4       |    25.2     | 1775 |     65.6      | 32.7  |                                                                                                                            -                                                                                                                             |
| LLaVA-v1.5-7B |  XTuner  |       68.6        |       68.0       |       61.5        |       61.4       |    26.5     | 1786 |     65.8      | 31.4  | [Pretrain](./vicuna_7b_v15_clip_vit_large_p14_336/pretrain/llava_vicuna_7b_v15_clip_vit_large_p14_336_e1_gpu8_pretrain.py) / [Fine-tune](./vicuna_7b_v15_clip_vit_large_p14_336/finetune/llava_vicuna_7b_v15_clip_vit_large_p14_336_e1_gpu8_finetune.py) |

## æ•°æ®å‡†å¤‡

è¯·å‚è€ƒ[æ–‡æ¡£](../../../docs/zh_cn/user_guides/dataset_prepare.md#llava-dataset)ã€‚

## è®­ç»ƒæµç¨‹

LLaVA è®­ç»ƒä¸€å…±åˆ†ä¸ºä¸¤æ­¥ï¼šå¯¹é½æ¨¡å—é¢„è®­ç»ƒã€æŒ‡ä»¤è·Ÿéšå¾®è°ƒï¼ˆæœ¬æŒ‡å—ä»¥ 8 å¡è®­ç»ƒ LLaVA-InternLM ä¸ºä¾‹ï¼Œå®é™…ä½¿ç”¨æ—¶å¦‚é‡åˆ°æ˜¾å¡æ•°é‡ä¸è¶³ã€æ˜¾å­˜ä¸è¶³ç­‰æƒ…å†µå¯ä»¥é€‚å½“è°ƒä½ batchsize æ¥é™ä½æ˜¾å­˜å¼€é”€ï¼‰

é¢„è®­ç»ƒçš„ Projector é»˜è®¤ä¿å­˜åœ¨ `./work_dirs/llava_internlm_chat_7b_clip_vit_large_p14_336_e1_gpu8_pretrain`ï¼Œå¹¶ä¸”æŒ‡ä»¤å¾®è°ƒé˜¶æ®µå°†é»˜è®¤åœ¨æ­¤è·¯å¾„è½½å…¥ Projector æƒé‡ ï¼ˆ`iter_2181.pth`ï¼‰ã€‚

1. å¯¹é½æ¨¡å—è®­ç»ƒï¼ˆé»˜è®¤ä¿å­˜åœ¨ `./work_dirs/`ï¼‰

```bash
NPROC_PER_NODE=8 xtuner train llava_internlm_chat_7b_clip_vit_large_p14_336_e1_gpu8_pretrain --deepspeed deepspeed_zero2
```

2. æŒ‡ä»¤è·Ÿéšå¾®è°ƒï¼ˆé»˜è®¤ä¿å­˜åœ¨ `./work_dirs/`ï¼‰

```bash
NPROC_PER_NODE=8 xtuner train llava_internlm_chat_7b_qlora_clip_vit_large_p14_336_lora_e1_gpu8_finetune --deepspeed deepspeed_zero2
```

## æ¨¡å‹è½¬æ¢ï¼ˆå’Œåˆå¹¶ï¼‰

è®­ç»ƒåï¼Œæˆ‘ä»¬å°†è·å¾—ä¸€ç»„æƒé‡ï¼ˆå³ï¼Œ`iter_xxx.pth`ï¼Œä½†å®ƒå¹¶ä¸æ˜¯é€šç”¨çš„ HuggingFace æ ¼å¼ã€‚æˆ‘ä»¬éœ€è¦å¯¹å…¶è¿›è¡Œè½¬æ¢ã€‚

```bash
xtuner convert pth_to_hf $FINETUNE_CFG $PTH_PATH $SAVE_PATH
# e.g., xtuner convert pth_to_hf llava_internlm_chat_7b_qlora_clip_vit_large_p14_336_lora_e1_gpu8_finetune ./iter_5198.pth ./iter_5198_hf
```

æ­¤æ—¶ï¼Œæˆ‘ä»¬å°†è·å¾—æ‰€éœ€è¦çš„æ¨¡å‹ï¼ˆLLMæˆ–å¯¹åº”çš„ LoRAï¼‰ã€‚

ä¹‹åï¼Œå¦‚æœæƒ³è¦åˆå¹¶ LoRA è‡³ LLM æˆ– CLIP-ViT ä¸­ï¼Œè¯·ä½¿ç”¨ä¸‹åˆ—å‘½ä»¤ï¼š

```bash
(LLM) xtuner convert merge $LLM $LLM_ADAPTER $SAVE_PATH
(CLIP) xtuner convert merge $CLIP $CLIP_ADAPTER $SAVE_PATH --is-clip
```

## å¯¹è¯æµ‹è¯•

å¼€æºçš„ LLaVA-InternLM-7B æ¨¡å‹åœ¨ ğŸ¤— [HuggingFace](https://huggingface.co/xtuner/llava-internlm-7b) å’Œ ğŸ¤– [ModelScope](https://modelscope.cn/models/xtuner/llava-internlm-7b) éƒ½å¯ä»¥ä¸‹è½½ï¼Œæ‚¨å¯ä»¥åˆ©ç”¨ä¸‹åˆ—å‘½ä»¤å®ç°å›¾æ–‡é—®ç­”ï¼

```bash
xtuner chat internlm/internlm-chat-7b \
  --visual-encoder openai/clip-vit-large-patch14-336 \
  --llava xtuner/llava-internlm-7b \
  --prompt-template internlm_chat \
  --image $IMAGE_PATH
```

æ­¤å¤„ï¼Œ `--llava` è¯·ä¼ å…¥æ¨¡å‹è½¬æ¢é˜¶æ®µæ‰€è·å¾—çš„æƒé‡ï¼ˆç¤ºä¾‹ä¸­ä¸º `./epoch_1_hf`ï¼‰ã€‚

## è¯„æµ‹

XTuner çš„ LLaVA æ¨¡å‹å¯ä»¥åˆ©ç”¨ [VLMEvalKit](https://github.com/open-compass/VLMEvalKit) è¿›è¡Œè¯„æµ‹ã€‚

åŒæ—¶ï¼Œä¸ºäº†æ–¹ä¾¿ä½¿ç”¨ï¼ŒXTuner å†…ä¹Ÿé›†æˆäº† MMBench è¯„æµ‹ï¼Œæ‚¨å¯ä»¥é€šè¿‡ä¸‹åˆ—å‘½ä»¤ä¸‹è½½ MMBench è¯„æµ‹æ•°æ®é›†ï¼š

```
wget https://opencompass.openxlab.space/utils/VLMEval/MMBench_DEV_EN.tsv
wget https://opencompass.openxlab.space/utils/VLMEval/MMBench_TEST_EN.tsv
wget https://opencompass.openxlab.space/utils/VLMEval/MMBench_DEV_CN.tsv
wget https://opencompass.openxlab.space/utils/VLMEval/MMBench_TEST_CN.tsv
wget https://opencompass.openxlab.space/utils/VLMEval/CCBench.tsv
```

ä¹‹åï¼Œæ‚¨å¯ä»¥åˆ©ç”¨ä¸‹åˆ—å‘½ä»¤å®ç°è¯„æµ‹ï¼š

```bash
xtuner mmbench internlm/internlm-chat-7b \
  --visual-encoder openai/clip-vit-large-patch14-336 \
  --llava xtuner/llava-internlm-7b \
  --prompt-template internlm_chat \
  --data-path $DATA_PATH \
  --work-dir $RESULT_PATH
```

å…¶ä¸­ï¼Œ`$DATA_PATH` æŒ‡ä¸Šä¸€æ­¥éª¤æ‰€ä¸‹è½½çš„æŸä¸€ä¸ª tsv æ–‡ä»¶ï¼Œå¦‚ `MMBench_DEV_EN.tsv`ã€‚

è¯„æµ‹å®Œæˆåï¼Œè‹¥ä¸ºå¼€å‘é›†åˆ™ä¼šç›´æ¥æ‰“å°å‡ºç»“æœï¼›è‹¥ä¸ºæµ‹è¯•é›†ï¼Œåˆ™éœ€å°† mmbench_result.xlsx æäº¤è‡³ MMBench å®˜æ–¹å®Œæˆè¯„æµ‹å–å¾—ç²¾åº¦ç»“æœï¼

### Refcoco

è‹¥æ‚¨æƒ³è¦è¯„æµ‹ Refcoco æ•°æ®é›†ï¼Œæ‚¨éœ€è¦ä¸‹è½½è¯„æµ‹æ•°æ®æ–‡ä»¶ [é“¾æ¥](https://github.com/Vision-CAIR/MiniGPT-4/tree/main/eval_scripts/eval_data). ä¹‹åï¼Œæ‚¨å¯ä»¥åˆ©ç”¨ä¸‹åˆ—å‘½ä»¤å®ç°è¯„æµ‹ï¼š

```bash
xtuner eval_refcoco lmsys/vicuna-7b-v1.5 \
  --visual-encoder openai/clip-vit-large-patch14-336 \
  --llava $LLAVA_PATH \
  --prompt-template internlm_chat \
  --data-path $DATA_PATH \
  --work-dir $RESULT_PATH
```
